# Claude Code Multi-Provider Proxy Configuration
# IMPORTANT: Don't copy this to .env - use 'claude-proxy config' instead!
# Configuration is now stored securely in ~/.config/gemini-code/config.env
# This file is for reference only to show available options

# Required: Your Google AI Studio API key
# Get yours at: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your-google-ai-studio-key-here

# Optional: Model mappings for Claude Code aliases
BIG_MODEL=gemini-2.0-flash-exp      # For 'sonnet' or 'opus' requests (newer 2.0 model)
SMALL_MODEL=gemini-1.5-flash-latest # For 'haiku' requests

# Optional: Server settings
HOST=0.0.0.0
PORT=8082
LOG_LEVEL=WARNING  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# Optional: Performance and reliability settings
MAX_TOKENS_LIMIT=8192           # Max tokens for Gemini responses
REQUEST_TIMEOUT=90              # Request timeout in seconds
MAX_RETRIES=2                   # LiteLLM retries to Gemini
MAX_STREAMING_RETRIES=12        # Streaming-specific retry attempts

# Optional: Streaming control (use if experiencing issues)
FORCE_DISABLE_STREAMING=false     # Disable streaming globally
EMERGENCY_DISABLE_STREAMING=false # Emergency streaming disable
